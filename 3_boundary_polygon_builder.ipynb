{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boundary mask builder\n",
    "\n",
    "### Note: Use the epi-paint kernel for alphashape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this used for?\n",
    "- Once the boundary detection script is run, and the Lamin outline is clearly extracted, this notebook helps to build a polygon around the lamin.\n",
    "- This polygon is then used to extract the locs within the polygon from all the other channels and then save them for future processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow\n",
    "- Define the folder to the cleaned up data and the files.\n",
    "- Define the file with the boundary data.\n",
    "- Import the Lamin_boundary.hdf5 file and extract the localizations. \n",
    "- Use alphashape to build the polygon around the shape. This should export the polygon. \n",
    "- Use the polygon as a mask and then clean all the imaging channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import alphashape as alphashape\n",
    "from matplotlib.path import Path\n",
    "import numpy as _np\n",
    "import os.path as _ospath\n",
    "import os as _os\n",
    "import h5py as _h5py\n",
    "import yaml as _yaml\n",
    "from PyQt5.QtWidgets import QMessageBox as _QMessageBox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder and the files with the data\n",
    "\n",
    "folder = '' # Folder name for specific cell.\n",
    "file_extn = '.hdf5'\n",
    "file_names = [f for f in _os.listdir(folder) if f.endswith(file_extn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output folder\n",
    "\n",
    "parent_folder, working_folder = _ospath.split(folder)\n",
    "output_folder = _ospath.join(parent_folder, working_folder , 'Masked')\n",
    "if not _ospath.exists(output_folder):\n",
    "    _os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picasso Functions Used Here\n",
    "\n",
    "def load_locs(path, qt_parent=None):\n",
    "    with _h5py.File(path, \"r\") as locs_file:\n",
    "        locs = locs_file[\"locs\"][...]\n",
    "    locs = _np.rec.array(\n",
    "        locs, dtype=locs.dtype\n",
    "    )  # Convert to rec array with fields as attributes\n",
    "    info = load_info(path, qt_parent=qt_parent)\n",
    "    return locs, info\n",
    "\n",
    "class NoMetadataFileError(FileNotFoundError):\n",
    "    pass\n",
    "\n",
    "def load_info(path, qt_parent=None):\n",
    "    path_base, path_extension = _ospath.splitext(path)\n",
    "    filename = path_base + \".yaml\"\n",
    "    try:\n",
    "        with open(filename, \"r\") as info_file:\n",
    "            info = list(_yaml.load_all(info_file, Loader=_yaml.UnsafeLoader))\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"\\nAn error occured. Could not find metadata file:\\n{}\".format(filename))\n",
    "        if qt_parent is not None:\n",
    "            _QMessageBox.critical(\n",
    "                qt_parent,\n",
    "                \"An error occured\",\n",
    "                \"Could not find metadata file:\\n{}\".format(filename),\n",
    "            )\n",
    "        raise NoMetadataFileError(e)\n",
    "    return info\n",
    "\n",
    "def save_info(path, info, default_flow_style=False):\n",
    "    with open(path, \"w\") as file:\n",
    "        _yaml.dump_all(info, file, default_flow_style=default_flow_style)\n",
    "\n",
    "def ensure_sanity(locs, info):\n",
    "    \"\"\"Ensures that localizations are within the image dimensions\n",
    "    and have positive localization precisions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    locs : np.rec.array\n",
    "        Localizations list.\n",
    "    info : list of dicts\n",
    "        Localization metadata.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    locs : np.rec.array\n",
    "        Localizations that pass the sanity checks.\n",
    "    \"\"\"\n",
    "    \n",
    "    # no inf or nan:\n",
    "    locs = locs[\n",
    "        _np.all(\n",
    "            _np.array([_np.isfinite(locs[_]) for _ in locs.dtype.names]),\n",
    "            axis=0,\n",
    "        )\n",
    "    ]\n",
    "    # other sanity checks:\n",
    "    locs = locs[locs.x > 0]\n",
    "    locs = locs[locs.y > 0]\n",
    "    locs = locs[locs.x < info[0][\"Width\"]]\n",
    "    locs = locs[locs.y < info[0][\"Height\"]]\n",
    "    locs = locs[locs.lpx > 0]\n",
    "    locs = locs[locs.lpy > 0]\n",
    "    return locs\n",
    "\n",
    "def save_locs_withSuffix(path, locs, info, suffix=''):\n",
    "    locs = ensure_sanity(locs, info)\n",
    "    base, ext_locs = _ospath.splitext(path)\n",
    "    output_locs_path = base + '_' + suffix + ext_locs    \n",
    "    output_info_path = base + '_' + suffix + '.yaml'\n",
    "    with _h5py.File(output_locs_path, \"w\") as locs_file:\n",
    "        locs_file.create_dataset(\"locs\", data=locs)\n",
    "    save_info(output_info_path, info, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the file with the string 'boundary' in the file name\n",
    "\n",
    "for file in file_names:\n",
    "    if 'boundary' in file:\n",
    "        boundary_file = _ospath.join(folder, file)\n",
    "        print('The boundary file {} is found'.format(file))\n",
    "        file_names.remove(file)\n",
    "        break\n",
    "\n",
    "# Load the boundary data\n",
    "boundary_locs, boundary_info = load_locs(boundary_file)\n",
    "\n",
    "# Extract the x and y coordinates of the boundary\n",
    "boundary_x = boundary_locs['x']\n",
    "boundary_y = boundary_locs['y']\n",
    "\n",
    "alpha_points = _np.array([[_x, _y] for _x, _y in zip(boundary_x, boundary_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract polygon from the boundary data\n",
    "\n",
    "alpha_shape = alphashape.alphashape(alpha_points, 0.0)\n",
    "alpha_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coordinates of the polygon\n",
    "\n",
    "polygon_coords = _np.array(alpha_shape.exterior.coords)\n",
    "polygon_path = Path(polygon_coords)\n",
    "_np.savetxt(_ospath.join(output_folder, 'polygon_coords.csv'), polygon_coords, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the points inside the polygon for the other channels\n",
    "\n",
    "for file in file_names:\n",
    "    fpath = _ospath.join(folder, file)\n",
    "    locs, info = load_locs(fpath)\n",
    "    points = _np.column_stack((locs['x'], locs['y']))\n",
    "    inside_mask = polygon_path.contains_points(points)\n",
    "    filtered_locs = locs[inside_mask]\n",
    "    output_path = _ospath.join(output_folder, file)\n",
    "    save_locs_withSuffix(output_path, filtered_locs, info, suffix='Masked')\n",
    "    print('The file {} is processed'.format(file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epi-paint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
