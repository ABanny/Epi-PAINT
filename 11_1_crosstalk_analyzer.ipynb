{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crosstalk Analyzer\n",
    "\n",
    "#### Note: Use the picasso kernel only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this do?\n",
    "- Reads all the datafiles and the picks provided. \n",
    "- Builds a matrix with the number of localizations for each pick channel across all channels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow\n",
    "- Define folder and files with data and pick infomation. \n",
    "- Loop through each file and extract the total number of localizations in each pick set. \n",
    "- Plot the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies.\n",
    "\n",
    "import os as _os\n",
    "import os.path as _ospath\n",
    "import numpy as _np\n",
    "import pandas as _pd\n",
    "import yaml as _yaml\n",
    "from picasso import io as _io\n",
    "from picasso import postprocess as _postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder and files for data.\n",
    "\n",
    "folder_data = '/Users/abhinav/Library/CloudStorage/OneDrive-IndianInstituteofScience/Papers/zz_Msequences/Multiplexing/20250116/Hdf5'   # Directory containing data files.\n",
    "data_extn = '.hdf5'                                                                                                                     # Data file extension.\n",
    "data_files = [f for f in _os.listdir(folder_data) if f.endswith(data_extn)]                                                             # List all the file with the given extension in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder and files for the pick files.\n",
    "\n",
    "folder_picks = '/Users/abhinav/Library/CloudStorage/OneDrive-IndianInstituteofScience/Papers/zz_Msequences/Multiplexing/20250116/Yaml'  # Directory containing the pick positions.\n",
    "pick_extn = '.yaml'                                                                                                                     # Pick information file extension.\n",
    "pick_files = [f for f in _os.listdir(folder_picks) if f.endswith(pick_extn) and 'picks' in f]                                           # List all the file with the given extension in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used in this script. (Adapted from picasso)\n",
    "\n",
    "def read_pick_locations(pick_file):                                                                                                     # Assumes that picks are circular.\n",
    "    with open(pick_file, 'r') as f:                                                                                                     # Read the picks from the yaml file.\n",
    "        regions = _yaml.full_load(f)\n",
    "    picks = regions['Centers']                                                                                                          # Centers provide the coordinates for the pick locations.\n",
    "    pick_size = regions['Diameter']                                                                                                     # Defines the diameter of the pick.\n",
    "    pick_shape = 'Circle'                                                                                                               # Defines the shape of the pick.\n",
    "    return picks, pick_size, pick_shape                                                                                                 # Return the pick locations, pick size and pick shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each data file and extract the picked locs number within each pick file and append to an array. \n",
    "\n",
    "rows = set()\n",
    "columns = set()\n",
    "data = {}\n",
    "\n",
    "for file in data_files:                                                                                                                 # Loop over all the data files.\n",
    "    fpath = _ospath.join(folder_data, file)                                                                                             # Build the full path to the data file.\n",
    "    channel_name = file.split('_')[1]                                                                                                   # Extract the channel name from the file name.\n",
    "    rows.add(channel_name)                                                                                                              # Add the channel name as the row.\n",
    "    locs, info = _io.load_locs(fpath)                                                                                                   # Load the locs and info from the data file. \n",
    "    for pick_file in pick_files:                                                                                                        # Loop through every pick regions to calculate the number of locs per pick.\n",
    "        pick_file_path = _ospath.join(folder_picks, pick_file)                                                                          # Build the full path to the pick file.\n",
    "        pick_name = pick_file.split('_')[0]                                                                                             # Extract the pick name from the pick file name.\n",
    "        columns.add(pick_name)                                                                                                          # Add the pick name as a column.\n",
    "        picks, pick_size, pick_shape = read_pick_locations(pick_file_path)                                                              # Read the information stored in the pick yaml file.\n",
    "        picked_locs = _postprocess.picked_locs(locs, info, picks, pick_shape, pick_size=pick_size/2, add_group=False)                   # Calculate the number of localizations within each pick.\n",
    "        picked_locs = _np.concatenate(picked_locs)                                                                                      # Concatenate the picked locs into a single array.\n",
    "        number_locs_per_pick = len(picked_locs)/len(picks)                                                                              # Count the number of locs per pick.\n",
    "        data[(channel_name, pick_name)] = number_locs_per_pick                                                                          # Store the measurement in the data dictionary.\n",
    "        print(f'Channel: {channel_name}, Pick: {pick_name}, Number of locs per pick: {number_locs_per_pick}')                           # Print the status of the loop.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each data file and extract the picked locs number within each pick file and append to an array. \n",
    "\n",
    "rows = set()\n",
    "columns = set()\n",
    "data_individual = {}\n",
    "\n",
    "for file in data_files:                                                                                                                 # Loop over all the data files.\n",
    "    fpath = _ospath.join(folder_data, file)                                                                                             # Build the full path to the data file.\n",
    "    channel_name = file.split('_')[1]                                                                                                   # Extract the channel name from the file name.\n",
    "    rows.add(channel_name)                                                                                                              # Add the channel name as the row.\n",
    "    locs, info = _io.load_locs(fpath)                                                                                                   # Load the locs and info from the data file. \n",
    "    individual_counts = []                                                                                       \n",
    "    for pick_file in pick_files:                                                                                                        # Loop through every pick regions to calculate the number of locs per pick.\n",
    "        pick_file_path = _ospath.join(folder_picks, pick_file)                                                                          # Build the full path to the pick file.\n",
    "        pick_name = pick_file.split('_')[0]                                                                                             # Extract the pick name from the pick file name.\n",
    "        columns.add(pick_name)                                                                                                          # Add the pick name as a column.\n",
    "        picks, pick_size, pick_shape = read_pick_locations(pick_file_path)                                                              # Read the information stored in the pick yaml file.\n",
    "        picked_locs = _postprocess.picked_locs(locs, info, picks, pick_shape, pick_size=pick_size/2, add_group=False)                   # Calculate the number of localizations within each pick.\n",
    "        counts = [len(pick) for pick in picked_locs]                                                                                    # Extract the counts of localizations in each pick.\n",
    "        individual_counts.extend([{'Channel': channel_name, 'Pick': pick_name, 'Count': count} for count in counts])                    # Store individual counts in a list.\n",
    "    data_individual[channel_name] = individual_counts                                                                                   # Store the individual counts in the data dictionary.\n",
    "    print(f'Channel: {channel_name}, Individual counts collected.')                                                                     # Print the status of the loop.\n",
    "\n",
    "all_data = []\n",
    "for channel, values in data_individual.items():                                                                                         # Loop through each channel and its values.\n",
    "    all_data.extend(values)                                                                                                             # Extend the all_data list with the individual counts.\n",
    "all_dataframe = _pd.DataFrame(all_data)                                                                                                 # Create a DataFrame from the all_data list.\n",
    "all_dataframe.to_csv('individual_counts.csv', index=False)                                                                              # Save the DataFrame to a CSV file.\n",
    "\n",
    "parent_folder, daughter_folder = _ospath.split(folder_data)\n",
    "output_path = _ospath.join(parent_folder, 'data_individual.csv')\n",
    "all_dataframe.to_csv(output_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe from the data.\n",
    "row_names = sorted(rows)\n",
    "column_names = sorted(columns)\n",
    "data_final = _pd.DataFrame(index=row_names, columns=column_names, dtype=_np.int32)\n",
    "\n",
    "for (row, column), value in data.items():\n",
    "    data_final.loc[row, column] = value\n",
    "\n",
    "data_final = data_final.loc[\n",
    "    sorted(data_final.index, key=lambda x: float('inf') if x == 'random' else int(x[1:])),\n",
    "    sorted(data_final.columns, key=lambda x: float('inf') if x == 'random' else int(x[1:]))\n",
    "]\n",
    "\n",
    "# Normalize data with the max along each row. \n",
    "normalized_data = data_final.div(data_final.max(axis=1), axis=0)\n",
    "parent_folder, daughter_folder = _ospath.split(folder_data)\n",
    "output_path = _ospath.join(parent_folder, 'data.csv')\n",
    "normalized_data.to_csv(output_path, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "picasso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
